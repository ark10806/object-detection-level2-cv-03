{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee48e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "from mmcv import Config\n",
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import inference_detector\n",
    "from mmdet.apis import single_gpu_test\n",
    "from mmcv.runner import load_checkpoint\n",
    "import os\n",
    "from mmcv.parallel import MMDataParallel\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b898417",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'swinB_cascade_rcnn_final.py' # model config 경로\n",
    "PATH = '/opt/ml/detection/mmdetection_new/work_dirs/swinB_smalldb_fold1' # 모델 저장된 폴더\n",
    "EPOCH ='epoch_36.pth' # model checkpoint 파일이름\n",
    "\n",
    "cfg =Config.fromfile(os.path.join(PATH,MODEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c7ec9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.model.test_cfg.rcnn.max_per_img=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aa1d1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# build dataset & dataloader\n",
    "cfg.data.test.test_mode = True\n",
    "size_min = 512\n",
    "size_max = 1024\n",
    "multi_scale_list = [(x,x) for x in range(size_min, size_max+1, 128)]\n",
    "cfg.data.test.pipeline[1]['img_scale'] = multi_scale_list # Resize\n",
    "cfg.data.test.ann_file = '/opt/ml/detection/dataset/test.json'\n",
    "\n",
    "test_dataset = build_dataset(cfg.data.test)\n",
    "test_loader = build_dataloader(\n",
    "        test_dataset,\n",
    "        samples_per_gpu=1,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=False,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3db0898",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ml/detection/mmdetection_new/mmdet/core/anchor/builder.py:17: UserWarning: ``build_anchor_generator`` would be deprecated soon, please use ``build_prior_generator`` \n",
      "  '``build_anchor_generator`` would be deprecated soon, please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_local loader\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "\n",
    "checkpoint_path = os.path.join(PATH,EPOCH)\n",
    "\n",
    "cfg.optimizer_config.grad_clip = dict(max_norm=35,norm_type=2)\n",
    "cfg.model.test_cfg.rpn.nms.type='soft_nms'\n",
    "cfg.model.test_cfg.rcnn.nms.type='soft_nms'\n",
    "cfg.model.test_cfg.rcnn.score_thr = 0.0\n",
    "\n",
    "# cfg.model.test_cfg.score_thr=0.0\n",
    "# cfg.model.test_cfg.nms.type='soft_nms'\n",
    "\n",
    "# build detector\n",
    "model = build_detector(cfg.model) \n",
    "# ckpt load\n",
    "checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu')\n",
    "\n",
    "model.CLASSES = test_dataset.CLASSES\n",
    "model = MMDataParallel(model.cuda(), device_ids=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90bb3d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                                  ] 0/4871, elapsed: 0s, ETA:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ml/detection/mmdetection_new/mmdet/core/anchor/anchor_generator.py:324: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` \n",
      "  warnings.warn('``grid_anchors`` would be deprecated soon. '\n",
      "/opt/ml/detection/mmdetection_new/mmdet/core/anchor/anchor_generator.py:361: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` \n",
      "  '``single_level_grid_anchors`` would be deprecated soon. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>] 4871/4871, 1.2 task/s, elapsed: 3903s, ETA:     0s"
     ]
    }
   ],
   "source": [
    "# output 계산\n",
    "output = single_gpu_test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74b2767f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/0000.jpg</td>\n",
       "      <td>0 0.20397568 653.04315 187.62665 689.4403 237....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/0001.jpg</td>\n",
       "      <td>0 0.0028966975 645.7086 643.6921 681.48425 839...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/0002.jpg</td>\n",
       "      <td>0 0.34168154 663.9275 291.31766 723.3013 321.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/0003.jpg</td>\n",
       "      <td>0 0.0005882114 104.22709 234.28113 143.96524 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/0004.jpg</td>\n",
       "      <td>0 0.022647388 426.91226 506.71216 473.95322 57...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_id                                   PredictionString\n",
       "0  test/0000.jpg  0 0.20397568 653.04315 187.62665 689.4403 237....\n",
       "1  test/0001.jpg  0 0.0028966975 645.7086 643.6921 681.48425 839...\n",
       "2  test/0002.jpg  0 0.34168154 663.9275 291.31766 723.3013 321.5...\n",
       "3  test/0003.jpg  0 0.0005882114 104.22709 234.28113 143.96524 3...\n",
       "4  test/0004.jpg  0 0.022647388 426.91226 506.71216 473.95322 57..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submission 양식에 맞게 output 후처리\n",
    "prediction_strings = []\n",
    "file_names = []\n",
    "coco = COCO(cfg.data.test.ann_file)\n",
    "img_ids = coco.getImgIds()\n",
    "\n",
    "class_num = 10\n",
    "for i, out in enumerate(output):\n",
    "    prediction_string = ''\n",
    "    image_info = coco.loadImgs(coco.getImgIds(imgIds=i))[0]\n",
    "    for j in range(class_num):\n",
    "        for o in out[j]:\n",
    "            prediction_string += str(j) + ' ' + str(o[4]) + ' ' + str(o[0]) + ' ' + str(o[1]) + ' ' + str(\n",
    "                o[2]) + ' ' + str(o[3]) + ' '\n",
    "        \n",
    "    prediction_strings.append(prediction_string)\n",
    "    file_names.append(image_info['file_name'])\n",
    "\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['image_id'] = file_names\n",
    "submission['PredictionString'] = prediction_strings\n",
    "submission.to_csv(f'{PATH}/{PATH.split(\"/\")[-2]}_submission_.csv', index=None)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41568df",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62146b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as func\n",
    "from mmdet.apis import inference_detector, show_result_pyplot\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as func\n",
    "import fiftyone as fo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdb468f",
   "metadata": {},
   "source": [
    "### image 한 장 visualization\n",
    "- 위에서 만들었던 submission 파일을 기반으로 visualization하는 것이 아니라, 하나씩 예측한 뒤 바로 visualization\n",
    "- submission 파일 기반 visualization은 아래 __fiftyone__을 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff6acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cfg = cfg\n",
    "idx = 11\n",
    "\n",
    "show_result_pyplot(model,test_dataset[idx]['img_metas'][0].data['filename'],output[idx])\n",
    "# or save the visualization results to image files\n",
    "#model.show_result(img, result, out_file='result.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057066ac",
   "metadata": {},
   "source": [
    "# dataset visualization\n",
    "- 위에서 만든 submission 파일 기반으로 visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d6b7373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 4871/4871 [1.2s elapsed, 0s remaining, 4.0K samples/s]         \n"
     ]
    }
   ],
   "source": [
    "dataset = fo.Dataset.from_images_dir(images_dir='/opt/ml/detection/dataset/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d716c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=true&handleId=0eb45857-36ca-4568-881b-9e7a29f23c41\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff0cc562510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "session = fo.launch_app(dataset) ## unlabeled dataset visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec969533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 4871/4871 [2.5m elapsed, 0s remaining, 26.3 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "predictions_view = dataset.limit(len(dataset))\n",
    "\n",
    "# Add predictions to samples\n",
    "with fo.ProgressBar() as pb:\n",
    "    for idx,sample in enumerate(pb(predictions_view)):\n",
    "        c, h, w = 3,1024,1024\n",
    "\n",
    "        #result = inference_detector(model, sample.filepath)\n",
    "        #show_result_pyplot(model, sample.filepath, result)\n",
    "        result = output[idx]\n",
    "        labels=[]\n",
    "        scores=[]\n",
    "        boxes=[]\n",
    "        for label,values in enumerate(result):\n",
    "            for pred in values:\n",
    "                labels.append(label)\n",
    "                scores.append(pred[-1])\n",
    "                boxes.append(list(pred[0:4]))\n",
    "\n",
    "        # Convert detections to FiftyOne format\n",
    "        detections = []\n",
    "        for label, score, box in zip(labels, scores, boxes):\n",
    "            # Convert to [top-left-x, top-left-y, width, height]\n",
    "            # in relative coordinates in [0, 1] x [0, 1]\n",
    "            x1, y1, x2, y2 = box\n",
    "            rel_box = [x1 / w, y1 / h, (x2 - x1) / w, (y2 - y1) / h]\n",
    "\n",
    "            detections.append(\n",
    "                fo.Detection(\n",
    "                    label=model.module.CLASSES[label],\n",
    "                    bounding_box=rel_box,\n",
    "                    confidence=score\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Save predictions to dataset\n",
    "        sample[\"predictions\"] = fo.Detections(detections=detections)\n",
    "        sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf39b15e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=true&handleId=480dcbfc-be99-4745-bd4e-bc5ddad4d1e9\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff0cce47350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "session.view = predictions_view\n",
    "session.freeze()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detection",
   "language": "python",
   "name": "detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
